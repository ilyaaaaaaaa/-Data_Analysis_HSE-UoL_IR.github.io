{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "1. Review of model evaluation procedures\n",
    "2. Steps for K-fold cross-validation\n",
    "3. Comparing cross-validation to train/test split\n",
    "4. Cross-validation recommendations\n",
    "5. Cross-validation example: parameter tuning\n",
    "6. Cross-validation example: model selection\n",
    "7. Cross-validation example: feature selection\n",
    "8. Improvements to cross-validation\n",
    "9. Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Review of model evaluation procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** Need a way to choose between machine learning models\n",
    "\n",
    "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
    "\n",
    "**Initial idea:** Train and test on the same data\n",
    "\n",
    "- But, maximizing **training accuracy** rewards overly complex models which **overfit** the training data\n",
    "\n",
    "**Alternative idea:** Train/test split\n",
    "\n",
    "- Split the dataset into two pieces, so that the model can be trained and tested on **different data**\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance\n",
    "- Problem with train/test split\n",
    "    - It provides a **high variance** estimate since changing which observations happen to be in the testing set can significantly change testing accuracy\n",
    "    - Testing accuracy can change a lot depending on a which observation happen to be in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# create X (features) and y (response)\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use train/test split with different random_state values\n",
    "# we can change the random_state values that changes the accuracy scores\n",
    "# the accuracy changes a lot\n",
    "# this is why testing accuracy is a high-variance estimate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=6)\n",
    "\n",
    "# check classification accuracy of KNN with K=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=5)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What if we created a bunch of train/test splits, calculated the testing accuracy for each, and averaged the results together?\n",
    "\n",
    "**Answer:** That's the essense of cross-validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Steps for K-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the dataset into K **equal** partitions (or \"folds\")\n",
    "    - So if k = 5 and dataset has 150 observations\n",
    "    - Each of the 5 folds would have 30 observations\n",
    "2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**\n",
    "    - Testing set = 30 observations (fold 1)\n",
    "    - Training set = 120 observations (folds 2-5)\n",
    "3. Calculate **testing accuracy**\n",
    "4. Repeat steps 2 and 3 K times, using a **different fold** as the testing set each time\n",
    "    - We will repeat the process 5 times\n",
    "    - 2nd iteration\n",
    "        - fold 2 would be the testing set\n",
    "        - union of fold 1, 3, 4, and 5 would be the training set\n",
    "    - 3rd iteration\n",
    "        - fold 3 would be the testing set\n",
    "        - union of fold 1, 2, 4, and 5 would be the training set\n",
    "    - And so on...\n",
    "5. Use the **average testing accuracy** as the estimate of out-of-sample accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram of **5-fold cross-validation:**\n",
    "\n",
    "![5-fold cross-validation](images/07_cross_validation_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                   Training set obsevations                    Testing set observations\n",
      "    1     [ 5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]        [0 1 2 3 4]       \n",
      "    2     [ 0  1  2  3  4 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24]        [5 6 7 8 9]       \n",
      "    3     [ 0  1  2  3  4  5  6  7  8  9 15 16 17 18 19 20 21 22 23 24]     [10 11 12 13 14]     \n",
      "    4     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 20 21 22 23 24]     [15 16 17 18 19]     \n",
      "    5     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]     [20 21 22 23 24]     \n"
     ]
    }
   ],
   "source": [
    "# simulate splitting a dataset of 25 observations into 5 folds\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "\n",
    "# print the contents of each training and testing set\n",
    "# ^ - forces the field to be centered within the available space\n",
    "# .format() - formats the string similar to %s or %n\n",
    "# enumerate(sequence, start=0) - returns an enumerate object\n",
    "print('{} {:^61} {}'.format('Iteration', \n",
    "    'Training set obsevations', 'Testing set observations'))\n",
    "\n",
    "for iteration, data in enumerate(kf.split(X[:25], y[:25]), start=1):\n",
    "    print('{!s:^9} {} {!s:^25}'.format(iteration, data[0], data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset contains **25 observations** (numbered 0 through 24)\n",
    "- 5-fold cross-validation, thus it runs for **5 iterations**\n",
    "- For each iteration, every observation is either in the training set or the testing set, **but not both**\n",
    "- Every observation is in the testing set **exactly once**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Comparing cross-validation to train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of **cross-validation:**\n",
    "\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    "- More \"efficient\" use of data\n",
    "    - This is because every observation is used for both training and testing\n",
    "\n",
    "Advantages of **train/test split:**\n",
    "\n",
    "- Runs K times faster than K-fold cross-validation\n",
    "    - This is because K-fold cross-validation repeats the train/test split K-times\n",
    "- Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cross-validation recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. K can be any number, but **K=10** is generally recommended\n",
    "    - This has been shown experimentally to produce the best out-of-sample estimate\n",
    "2. For classification problems, **stratified sampling** is recommended for creating the folds\n",
    "    - Each response class should be represented with equal proportions in each of the K folds\n",
    "        - If dataset has 2 response classes \n",
    "            - Spam/Ham\n",
    "            - 20% observation = ham\n",
    "            - Each cross-validation fold should consist of exactly 20% ham\n",
    "    - scikit-learn's `cross_val_score` function does this by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cross-validation example: parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset\n",
    "- We want to choose the best tuning parameters that best generalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
    "# k = 5 for KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Use cross_val_score function\n",
    "# We are passing the entirety of X and y, not X_train or y_train, \n",
    "# it takes care of splitting the data\n",
    "# cv=10 for 10 folds\n",
    "# scoring='accuracy' for evaluation metric - althought they are many\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the first iteration, the accuracy is 100%\n",
    "- Second iteration, the accuracy is 93% and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cross_val_score executes the first 4 steps of k-fold cross-validation steps which I have broken down to 7 steps here in detail**\n",
    "1. Split the dataset (X and y) into K=10 **equal** partitions (or \"folds\")\n",
    "2. Train the KNN model on union of folds 2 to 10 (training set)\n",
    "3. Test the model on fold 1 (testing set) and calculate testing accuracy\n",
    "4. Train the KNN model on union of fold 1 and fold 3 to 10 (training set)\n",
    "5. Test the model on fold 2 (testing set) and calculate testing accuracy\n",
    "6. It will do this on 8 more times\n",
    "7. When finished, it will return the 10 testing accuracy scores as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "# numpy array has a method mean()\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here is to find the optimal value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f41f97e17b047a1abf89bdf6bb4349a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96, 0.9533333333333334, 0.9666666666666666, 0.9666666666666666, 0.9666666666666668, 0.9666666666666668, 0.9666666666666668, 0.9666666666666668, 0.9733333333333334, 0.9666666666666668, 0.9666666666666668, 0.9733333333333334, 0.9800000000000001, 0.9733333333333334, 0.9733333333333334, 0.9733333333333334, 0.9733333333333334, 0.9800000000000001, 0.9733333333333334, 0.9800000000000001, 0.9666666666666666, 0.9666666666666666, 0.9733333333333334, 0.96, 0.9666666666666666, 0.96, 0.9666666666666666, 0.9533333333333334, 0.9533333333333334, 0.9533333333333334]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "\n",
    "# range of k we want to try\n",
    "k_range = range(1, 31)\n",
    "# empty list to store scores\n",
    "k_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in tqdm(k_range):\n",
    "    # 2. run KNeighborsClassifier with k neighbours\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # 3. obtain cross_val_score for KNeighborsClassifier with k neighbours\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for k neighbors to k_scores list\n",
    "    k_scores.append(scores.mean())\n",
    "    \n",
    "\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of list 30\n",
      "Max of list 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# in essence, this is basically running the k-fold cross-validation method 30 times because we want to run through K values from 1 to 30\n",
    "# we should have 30 scores here\n",
    "print('Length of list', len(k_scores))\n",
    "print('Max of list', max(k_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross-validated accuracy')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot how accuracy changes as we vary k\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "# plt.plot(x_axis, y_axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-validated accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum cv accuracy occurs from k=13 to k=20\n",
    "- The general shape of the curve is an upside down yield\n",
    "    - This is quite typical when examining the model complexity and accuracy\n",
    "    - This is an example of bias-variance trade off\n",
    "        - Low values of k (low bias, high variance)\n",
    "            - The 1-Nearest Neighbor classifier is the most complex nearest neighbor model\n",
    "            - It has the most jagged decision boundary, and is most likely to overfit\n",
    "        - High values of k (high bias, low variance) \n",
    "            - underfit\n",
    "        - Best value is the middle of k (most likely to generalize out-of-sample data)\n",
    "            - just right\n",
    "    \n",
    "- The best value of k\n",
    "    - Higher values of k produce less complex model\n",
    "        - So we will choose 20 as our best KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Cross-validation example: model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Compare the best KNN model with logistic regression on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with the best KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "# Instead of saving 10 scores in object named score and calculating mean\n",
    "# We're just calculating the mean directly on the results\n",
    "print(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print(cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that KNN is likely a better choice than logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Cross-validation example: feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Select whether the Newspaper feature should be included in the linear regression model on the advertising dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the advertising dataset\n",
    "data = pd.read_csv('Advertising.csv', index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Python list of three feature names\n",
    "feature_cols = ['TV', 'Radio', 'Newspaper']\n",
    "\n",
    "# use the list to select a subset of the DataFrame (X)\n",
    "X = data[feature_cols]\n",
    "\n",
    "# select the Sales column as the response (y)\n",
    "# since we're selecting only one column, we can select the attribute using .attribute\n",
    "y = data.Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.56038438 -3.29767522 -2.08943356 -2.82474283 -1.3027754  -1.74163618\n",
      " -8.17338214 -2.11409746 -3.04273109 -2.45281793]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with all three features\n",
    "# instantiate model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# store scores in scores object\n",
    "# we can't use accuracy as our evaluation metric since that's only relevant for classification problems\n",
    "# RMSE is not directly available so we will use MSE\n",
    "scores = cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import SCORERS\n",
    "sorted(SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE should be positive\n",
    "- But why is the MSE here negative?\n",
    "- MSE is a loss function\n",
    "    - It is something we want to minimize\n",
    "    - A design decision was made so that the results are made negative\n",
    "    - The best results would be the largest number (the least negative) so we can still maximize similar to classification accuracy\n",
    "- Classification Accuracy is a reward function\n",
    "    - It is something we want to maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.56038438 3.29767522 2.08943356 2.82474283 1.3027754  1.74163618\n",
      " 8.17338214 2.11409746 3.04273109 2.45281793]\n"
     ]
    }
   ],
   "source": [
    "# fix the sign of MSE scores\n",
    "mse_scores = -scores\n",
    "print(mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.88689808 1.81595022 1.44548731 1.68069713 1.14139187 1.31971064\n",
      " 2.85891276 1.45399362 1.7443426  1.56614748]\n"
     ]
    }
   ],
   "source": [
    "# convert from MSE to RMSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "print(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6913531708051792\n"
     ]
    }
   ],
   "source": [
    "# calculate the average RMSE\n",
    "print(rmse_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6796748419090766\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with two features (excluding Newspaper)\n",
    "feature_cols = ['TV', 'Radio']\n",
    "X = data[feature_cols]\n",
    "print(np.sqrt(-cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Newspaper\n",
    "- Average RMSE = 1.68\n",
    "- lower number than with model with Newspaper\n",
    "    - RMSE is something we want to minimize\n",
    "    - So the model excluding Newspaper is a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Improvements to cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeated cross-validation**\n",
    "\n",
    "- Repeat cross-validation multiple times (with **different random splits** of the data) and average the results\n",
    "- More reliable estimate of out-of-sample performance by **reducing the variance** associated with a single trial of cross-validation\n",
    "\n",
    "**Creating a hold-out set**\n",
    "\n",
    "- \"Hold out\" a portion of the data **before** beginning the model building process\n",
    "- Locate the best model using cross-validation on the remaining data, and test it **using the hold-out set**\n",
    "- More reliable estimate of out-of-sample performance since hold-out set is **truly out-of-sample**\n",
    "\n",
    "**Feature engineering and selection within cross-validation iterations**\n",
    "\n",
    "- Normally, feature engineering and selection occurs **before** cross-validation\n",
    "- Instead, perform all feature engineering and selection **within each cross-validation iteration**\n",
    "- More reliable estimate of out-of-sample performance since it **better mimics** the application of the model to out-of-sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Resources\n",
    "\n",
    "- scikit-learn documentation: [Cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html), [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- scikit-learn issue on GitHub: [MSE is negative when returned by cross_val_score](https://github.com/scikit-learn/scikit-learn/issues/2439)\n",
    "- Section 5.1 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (11 pages) and related videos: [K-fold and leave-one-out cross-validation](https://www.youtube.com/watch?v=nZAM5OXrktY) (14 minutes), [Cross-validation the right and wrong ways](https://www.youtube.com/watch?v=S06JpVoNaA0) (10 minutes)\n",
    "- Scott Fortmann-Roe: [Accurately Measuring Model Prediction Error](http://scott.fortmann-roe.com/docs/MeasuringError.html)\n",
    "- Machine Learning Mastery: [An Introduction to Feature Selection](http://machinelearningmastery.com/an-introduction-to-feature-selection/)\n",
    "- Harvard CS109: [Cross-Validation: The Right and Wrong Way](https://github.com/cs109/content/blob/master/lec_10_cross_val.ipynb)\n",
    "- Journal of Cheminformatics: [Cross-validation pitfalls when selecting and assessing regression and classification models](http://www.jcheminf.com/content/pdf/1758-2946-6-10.pdf)\n",
    "\n",
    "_This tutorial is derived from Data School's Machine Learning with scikit-learn tutorial. Ritchie Ng added notes so anyone, including myself, can refer to this tutorial without watching the videos._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "355.917px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
