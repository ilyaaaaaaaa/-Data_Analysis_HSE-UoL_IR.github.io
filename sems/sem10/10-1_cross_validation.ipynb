{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics\n",
    "1. Review of model evaluation procedures\n",
    "2. Steps for K-fold cross-validation\n",
    "3. Comparing cross-validation to train/test split\n",
    "4. Cross-validation recommendations\n",
    "5. Cross-validation example: parameter tuning\n",
    "6. Cross-validation example: model selection\n",
    "7. Cross-validation example: feature selection\n",
    "8. Improvements to cross-validation\n",
    "9. Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This tutorial is derived from Data School's Machine Learning with scikit-learn tutorial. Ritchie Ng added notes so anyone, including myself, can refer to this tutorial without watching the videos._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Review of model evaluation procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivation:** Need a way to choose between machine learning models\n",
    "\n",
    "- Goal is to estimate likely performance of a model on **out-of-sample data**\n",
    "\n",
    "**Initial idea:** Train and test on the same data\n",
    "\n",
    "- But, maximizing **training accuracy** rewards overly complex models which **overfit** the training data\n",
    "\n",
    "**Alternative idea:** Train/test split\n",
    "\n",
    "- Split the dataset into two pieces, so that the model can be trained and tested on **different data**\n",
    "- **Testing accuracy** is a better estimate than training accuracy of out-of-sample performance\n",
    "- Problem with train/test split\n",
    "    - It provides a **high variance** estimate since changing which observations happen to be in the testing set can significantly change testing accuracy\n",
    "    - Testing accuracy can change a lot depending on a which observation happen to be in the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the iris data\n",
    "iris = load_iris()\n",
    "\n",
    "# create X (features) and y (response)\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use train/test split with different random_state values\n",
    "# we can change the random_state values that changes the accuracy scores\n",
    "# the accuracy changes a lot\n",
    "# this is why testing accuracy is a high-variance estimate\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=6)\n",
    "\n",
    "# check classification accuracy of KNN with K=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What if we created a bunch of train/test splits, calculated the testing accuracy for each, and averaged the results together?\n",
    "\n",
    "**Answer:** That's the essense of cross-validation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Steps for K-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split the dataset into K **equal** partitions (or \"folds\")\n",
    "    - So if k = 5 and dataset has 150 observations\n",
    "    - Each of the 5 folds would have 30 observations\n",
    "2. Use fold 1 as the **testing set** and the union of the other folds as the **training set**\n",
    "    - Testing set = 30 observations (fold 1)\n",
    "    - Training set = 120 observations (folds 2-5)\n",
    "3. Calculate **testing accuracy**\n",
    "4. Repeat steps 2 and 3 K times, using a **different fold** as the testing set each time\n",
    "    - We will repeat the process 5 times\n",
    "    - 2nd iteration\n",
    "        - fold 2 would be the testing set\n",
    "        - union of fold 1, 3, 4, and 5 would be the training set\n",
    "    - 3rd iteration\n",
    "        - fold 3 would be the testing set\n",
    "        - union of fold 1, 2, 4, and 5 would be the training set\n",
    "    - And so on...\n",
    "5. Use the **average testing accuracy** as the estimate of out-of-sample accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diagram of **5-fold cross-validation:**\n",
    "\n",
    "![5-fold cross-validation](images/07_cross_validation_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration                   Training set obsevations                    Testing set observations\n",
      "    1     [ 30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "    2     [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] [30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "    3     [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] [60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "    4     [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      " 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149] [ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "    5     [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119] [120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n"
     ]
    }
   ],
   "source": [
    "# simulate splitting a dataset of 25 observations into 5 folds\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "\n",
    "# print the contents of each training and testing set\n",
    "# ^ - forces the field to be centered within the available space\n",
    "# .format() - formats the string similar to %s or %n\n",
    "# enumerate(sequence, start=0) - returns an enumerate object\n",
    "print('{} {:^61} {}'.format('Iteration', 'Training set obsevations', 'Testing set observations'))\n",
    "for iteration, data in enumerate(kf.split(X, y), start=1):\n",
    "    print('{!s:^9} {} {!s:^25}'.format(iteration, data[0], data[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset contains **25 observations** (numbered 0 through 24)\n",
    "- 5-fold cross-validation, thus it runs for **5 iterations**\n",
    "- For each iteration, every observation is either in the training set or the testing set, **but not both**\n",
    "- Every observation is in the testing set **exactly once**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Comparing cross-validation to train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of **cross-validation:**\n",
    "\n",
    "- More accurate estimate of out-of-sample accuracy\n",
    "- More \"efficient\" use of data\n",
    "    - This is because every observation is used for both training and testing\n",
    "\n",
    "Advantages of **train/test split:**\n",
    "\n",
    "- Runs K times faster than K-fold cross-validation\n",
    "    - This is because K-fold cross-validation repeats the train/test split K-times\n",
    "- Simpler to examine the detailed results of the testing process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cross-validation recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. K can be any number, but **K=10** is generally recommended\n",
    "    - This has been shown experimentally to produce the best out-of-sample estimate\n",
    "2. For classification problems, **stratified sampling** is recommended for creating the folds\n",
    "    - Each response class should be represented with equal proportions in each of the K folds\n",
    "        - If dataset has 2 response classes \n",
    "            - Spam/Ham\n",
    "            - 20% observation = ham\n",
    "            - Each cross-validation fold should consist of exactly 20% ham\n",
    "    - scikit-learn's `cross_val_score` function does this by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Cross-validation example: parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Select the best tuning parameters (aka \"hyperparameters\") for KNN on the iris dataset\n",
    "- We want to choose the best tuning parameters that best generalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.93333333 1.         1.         0.86666667 0.93333333\n",
      " 0.93333333 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with K=5 for KNN (the n_neighbors parameter)\n",
    "# k = 5 for KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Use cross_val_score function\n",
    "# We are passing the entirety of X and y, not X_train or y_train, it takes care of splitting the dat\n",
    "# cv=10 for 10 folds\n",
    "# scoring='accuracy' for evaluation metric - althought they are many\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the first iteration, the accuracy is 100%\n",
    "- Second iteration, the accuracy is 93% and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cross_val_score executes the first 4 steps of k-fold cross-validation steps which I have broken down to 7 steps here in detail**\n",
    "1. Split the dataset (X and y) into K=10 **equal** partitions (or \"folds\")\n",
    "2. Train the KNN model on union of folds 2 to 10 (training set)\n",
    "3. Test the model on fold 1 (testing set) and calculate testing accuracy\n",
    "4. Train the KNN model on union of fold 1 and fold 3 to 10 (training set)\n",
    "5. Test the model on fold 2 (testing set) and calculate testing accuracy\n",
    "6. It will do this on 8 more times\n",
    "7. When finished, it will return the 10 testing accuracy scores as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "# use average accuracy as an estimate of out-of-sample accuracy\n",
    "# numpy array has a method mean()\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here is to find the optimal value of K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96, 0.9533333333333334, 0.9666666666666666, 0.9666666666666666, 0.9666666666666668, 0.9666666666666668, 0.9666666666666668, 0.9666666666666668, 0.9733333333333334, 0.9666666666666668, 0.9666666666666668, 0.9733333333333334, 0.9800000000000001, 0.9733333333333334, 0.9733333333333334, 0.9733333333333334, 0.9733333333333334, 0.9800000000000001, 0.9733333333333334, 0.9800000000000001, 0.9666666666666666, 0.9666666666666666, 0.9733333333333334, 0.96, 0.9666666666666666, 0.96, 0.9666666666666666, 0.9533333333333334, 0.9533333333333334, 0.9533333333333334]\n"
     ]
    }
   ],
   "source": [
    "# search for an optimal value of K for KNN\n",
    "\n",
    "# range of k we want to try\n",
    "k_range = range(1, 31)\n",
    "# empty list to store scores\n",
    "k_scores = []\n",
    "\n",
    "# 1. we will loop through reasonable values of k\n",
    "for k in k_range:\n",
    "    # 2. run KNeighborsClassifier with k neighbours\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    # 3. obtain cross_val_score for KNeighborsClassifier with k neighbours\n",
    "    scores = cross_val_score(knn, X, y, cv=10, scoring='accuracy')\n",
    "    # 4. append mean of scores for k neighbors to k_scores list\n",
    "    k_scores.append(scores.mean())\n",
    "    \n",
    "\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of list 30\n",
      "Max of list 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# in essence, this is basically running the k-fold cross-validation method 30 times because we want to run through K values from 1 to 30\n",
    "# we should have 30 scores here\n",
    "print('Length of list', len(k_scores))\n",
    "print('Max of list', max(k_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cross-validated accuracy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot how accuracy changes as we vary k\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# plot the value of K for KNN (x-axis) versus the cross-validated accuracy (y-axis)\n",
    "# plt.plot(x_axis, y_axis)\n",
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Cross-validated accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum cv accuracy occurs from k=13 to k=20\n",
    "- The general shape of the curve is an upside down yield\n",
    "    - This is quite typical when examining the model complexity and accuracy\n",
    "    - This is an example of bias-variance trade off\n",
    "        - Low values of k (low bias, high variance)\n",
    "            - The 1-Nearest Neighbor classifier is the most complex nearest neighbor model\n",
    "            - It has the most jagged decision boundary, and is most likely to overfit\n",
    "        - High values of k (high bias, low variance) \n",
    "            - underfit\n",
    "        - Best value is the middle of k (most likely to generalize out-of-sample data)\n",
    "            - just right\n",
    "    \n",
    "- The best value of k\n",
    "    - Higher values of k produce less complex model\n",
    "        - So we will choose 20 as our best KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Cross-validation example: model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal:** Compare the best KNN model with logistic regression on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with the best KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "# Instead of saving 10 scores in object named score and calculating mean\n",
    "# We're just calculating the mean directly on the results\n",
    "print(cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a18509896/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/a18509896/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/a18509896/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/a18509896/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/a18509896/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "print(cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude that KNN is likely a better choice than logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Cross-validation example: feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goal**: Select whether the Newspaper feature should be included in the linear regression model on the advertising dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the advertising dataset\n",
    "data = pd.read_csv('Advertising.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Python list of three feature names\n",
    "feature_cols = ['TV', 'Radio', 'Newspaper']\n",
    "\n",
    "# use the list to select a subset of the DataFrame (X)\n",
    "X = data[feature_cols]\n",
    "\n",
    "# select the Sales column as the response (y)\n",
    "# since we're selecting only one column, we can select the attribute using .attribute\n",
    "y = data.Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.56038438 -3.29767522 -2.08943356 -2.82474283 -1.3027754  -1.74163618\n",
      " -8.17338214 -2.11409746 -3.04273109 -2.45281793]\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with all three features\n",
    "# instantiate model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# store scores in scores object\n",
    "# we can't use accuracy as our evaluation metric since that's only relevant for classification problems\n",
    "# RMSE is not directly available so we will use MSE\n",
    "scores = cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE should be positive\n",
    "- But why is the MSE here negative?\n",
    "- MSE is a loss function\n",
    "    - It is something we want to minimize\n",
    "    - A design decision was made so that the results are made negative\n",
    "    - The best results would be the largest number (the least negative) so we can still maximize similar to classification accuracy\n",
    "- Classification Accuracy is a reward function\n",
    "    - It is something we want to maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.56038438 3.29767522 2.08943356 2.82474283 1.3027754  1.74163618\n",
      " 8.17338214 2.11409746 3.04273109 2.45281793]\n"
     ]
    }
   ],
   "source": [
    "# fix the sign of MSE scores\n",
    "mse_scores = -scores\n",
    "print(mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.88689808 1.81595022 1.44548731 1.68069713 1.14139187 1.31971064\n",
      " 2.85891276 1.45399362 1.7443426  1.56614748]\n"
     ]
    }
   ],
   "source": [
    "# convert from MSE to RMSE\n",
    "rmse_scores = np.sqrt(mse_scores)\n",
    "print(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6913531708051792\n"
     ]
    }
   ],
   "source": [
    "# calculate the average RMSE\n",
    "print(rmse_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6796748419090766\n"
     ]
    }
   ],
   "source": [
    "# 10-fold cross-validation with two features (excluding Newspaper)\n",
    "feature_cols = ['TV', 'Radio']\n",
    "X = data[feature_cols]\n",
    "print(np.sqrt(-cross_val_score(lm, X, y, cv=10, scoring='neg_mean_squared_error')).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Newspaper\n",
    "- Average RMSE = 1.68\n",
    "- lower number than with model with Newspaper\n",
    "    - RMSE is something we want to minimize\n",
    "    - So the model excluding Newspaper is a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Improvements to cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Repeated cross-validation**\n",
    "\n",
    "- Repeat cross-validation multiple times (with **different random splits** of the data) and average the results\n",
    "- More reliable estimate of out-of-sample performance by **reducing the variance** associated with a single trial of cross-validation\n",
    "\n",
    "**Creating a hold-out set**\n",
    "\n",
    "- \"Hold out\" a portion of the data **before** beginning the model building process\n",
    "- Locate the best model using cross-validation on the remaining data, and test it **using the hold-out set**\n",
    "- More reliable estimate of out-of-sample performance since hold-out set is **truly out-of-sample**\n",
    "\n",
    "**Feature engineering and selection within cross-validation iterations**\n",
    "\n",
    "- Normally, feature engineering and selection occurs **before** cross-validation\n",
    "- Instead, perform all feature engineering and selection **within each cross-validation iteration**\n",
    "- More reliable estimate of out-of-sample performance since it **better mimics** the application of the model to out-of-sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Resources\n",
    "\n",
    "- scikit-learn documentation: [Cross-validation](http://scikit-learn.org/stable/modules/cross_validation.html), [Model evaluation](http://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "- scikit-learn issue on GitHub: [MSE is negative when returned by cross_val_score](https://github.com/scikit-learn/scikit-learn/issues/2439)\n",
    "- Section 5.1 of [An Introduction to Statistical Learning](http://www-bcf.usc.edu/~gareth/ISL/) (11 pages) and related videos: [K-fold and leave-one-out cross-validation](https://www.youtube.com/watch?v=nZAM5OXrktY) (14 minutes), [Cross-validation the right and wrong ways](https://www.youtube.com/watch?v=S06JpVoNaA0) (10 minutes)\n",
    "- Scott Fortmann-Roe: [Accurately Measuring Model Prediction Error](http://scott.fortmann-roe.com/docs/MeasuringError.html)\n",
    "- Machine Learning Mastery: [An Introduction to Feature Selection](http://machinelearningmastery.com/an-introduction-to-feature-selection/)\n",
    "- Harvard CS109: [Cross-Validation: The Right and Wrong Way](https://github.com/cs109/content/blob/master/lec_10_cross_val.ipynb)\n",
    "- Journal of Cheminformatics: [Cross-validation pitfalls when selecting and assessing regression and classification models](http://www.jcheminf.com/content/pdf/1758-2946-6-10.pdf)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "355.917px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
